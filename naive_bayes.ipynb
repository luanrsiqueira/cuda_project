{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./datasets/teste_08_06.csv')\n",
    "df1 = df1[['compute_version','registers','smem','cmem','num_of_cores','L2','bandwith','theoretical_flops','AppId','number_of_lines_kernel','occupancy','input_size','duration','block_x']]\n",
    "df1 = df1.select_dtypes(exclude=['object'])\n",
    "df1 = df1.sort_values(by='input_size', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12   7   9   6   8  27  25  28  22  14  17  15  19   3  11  13  10   4\n",
      "   1   0   2   5  26  18  36  33  23  40  47  21  64  44  34  30  24  61\n",
      "  57  55  63  48  46  29  38  41  20  16  32  35  69  74 100  31  90  39\n",
      "  96  81  56  51  59  37 101  53  78  71  88  54  43  50  65  66  67  42\n",
      "  76 136 138  77  49 125  86  84 110  93 134  60  58  52  45  75  89 105\n",
      "  80 108  97 121  70  83  92 117 135 171 142 122 177 111 102 158  68 113\n",
      "  72  62  82 114 107  98 157 160 103 126  79 141 144 131 129 139  99 153\n",
      " 120  85 112 118  87 123 191 194 128 178 167  73  94 199 211 150 164 207\n",
      " 143 243 162  91 148 115 106 154 222 116 146 224 130 179 200 247 166 232\n",
      "  95 192 195 145 182 156 220 218 267 284 260 208 203 257 172 151 127 104\n",
      " 184 277 234 168 133 181 119 165 161 109 186 173 288 319 124 140 300 262\n",
      " 212 193 244 210 291 183 231 204 236 132 310 170 251 147 152 198 201 185\n",
      " 137 278 149 343 219 209 303 155 265 239 202 324 238 271 330 163 190 215\n",
      " 353 321 169 227 226 256 379 315 255 263 249 180 206 189 225 159 176 230\n",
      " 350 287 305 354 362 299 241 175 250 387 237 282 275 188 334 174 253 187\n",
      " 268 311 363 248 325 392 285 279 205 409 196 419 223 385 381 258 273 306\n",
      " 333 245 453 416 445 216 286 408 307 217 272 425 304 213 360 221 339 298\n",
      " 197 346 280 374 297 274 229 331 242 441 289 421 455 326 388 214 367 485\n",
      " 235 375 316 261 308 302 359 472 318 228 446 292 482 355 345 412 380 341\n",
      " 254 349 323 259 468 233 252 246 283 314 470 328 504 400 313 389 449 512\n",
      " 376 269 533 296 423 509 368 340 276 497 500 403 356 342 240 266 336 478\n",
      " 364 439 411 264 543 348 522 294 366 437 561 290 358 322 372 281 528 537\n",
      " 396 430 480 390 301 384 270 357 573 464 399 327 295 312 309 373 406 413\n",
      " 293 335 401 489 405 377 460 599 564 383 553 452 586 420 555 526 317 575\n",
      " 428 395 347 393 612 329 402 410 484 511 433 473 337 530 588 320 438 625\n",
      " 577 440 352 371 640 344 332 602 426 450 458 648 605 351 462 495 457 582\n",
      " 613 338 535 505 414 418 369 435 660 479 557 467 515 476 627 443 531 454\n",
      " 432 365 436 382 665 361 598 398 623 639 483 391 370 456 471 540 461 502\n",
      " 496 651 659 503 578 628 397 404 683 551 378 646 678 463 488 422 386 415\n",
      " 427 417 645 519 674 558 516 434 603 690 469 664 491 487 451 507 431 570\n",
      " 695 394 523 667 481 681 701 679 687 424 448 707 465 447 407 548 590 621\n",
      " 521 499 666 539 527 442 506 490 580 549 691 547 508 692 532 644 604 609\n",
      " 514 712 699 571 715 477 534 676 466 486 569 474 429 560 494 562 552 630\n",
      " 693 536 501 498 444 721 524 556 579 591 704 719 702 517 709 492 658 620\n",
      " 513 589 545 529 730 518 716 626 642 671 542 713 711 727 597 614 647 581\n",
      " 459 520 554 593 544 563 700 567 546 735 615 714 559 607 565 601 583 641\n",
      " 655 720 685 663 635 475 733 718 541 723 572 550 631 585 568 742 566 574\n",
      " 493 705 638 657 595 668 694 673 616 600 584 576 731 726 669 740 725 684\n",
      " 747 587 732 736 510 596 592 677 656 611 745 606 729 686 634 633 594 654\n",
      " 703 680 617 734 675 632 618 662 525 622 728 696 629 749 610 737 739 741\n",
      " 689 710 697 619 608 688 643 748 649 751 738 652 636 653 672 661 624 650\n",
      " 706 698 744 750 743 746 717 637 538 682 670 708 724 722]\n",
      "[  3   6   2   0   5   7   1   4   8  13  20  22  17  21  15  16  12  18\n",
      "  11  14   9  10  19  23  47  34  35  53  30  24  27  32  25  29  31  26\n",
      "  28  48  42  39  40  50  38  46  33  44  36  37  51  43  58  59  45  79\n",
      "  74  62  55  41  57  66  68  61  54  72  85  49  73  77  52  64  76  56\n",
      "  89  81  97  69  78  82  63 107  88  75  65  71  84 103 106  60  87  67\n",
      "  94 118 100 110  70  91 108 115 134 133  96 149 142 125 102 122  92 131\n",
      "  93 104  83 117  80 112 105  98 136  86  90 114 135 126 182 144 128 138\n",
      " 167 158 164 160 148 132 163 116 111 145 109 101  99 120  95 171 119 124\n",
      " 152 113 121 197 139 159 190 130 175 169 187 137 157 153 205 168 185 193\n",
      " 213 166 123 143 129 151 238 196 226 223 218 189 174 156 241 141 146 150\n",
      " 179 217 154 183 221 140 204 180 127 178 161 188 222 245 206 202 220 258\n",
      " 203 242 208 230 265 254 177 181 186 155 198 170 162 214 147 172 273 252\n",
      " 227 173 195 272 247 305 176 261 207 286 192 165 243 280 240 263 225 229\n",
      " 215 200 283 194 298 236 251 255 248 269 211 235 309 264 209 337 228 224\n",
      " 184 212 201 191 317 330 285 301 275 311 287 262 259 231 244 359 199 210\n",
      " 233 368 300 349 331 284 312 219 246 339 274 296 277 293 319 232 338 282\n",
      " 266 377 281 260 327 371 316 257 403 250 389 216 239 270 234 358 364 299\n",
      " 304 340 342 310 297 321 424 348 288 249 267 386 237 367 256 322 366 329\n",
      " 431 341 302 276 323 408 335 352 402 278 290 396 294 320 450 357 326 351\n",
      " 253 279 346 391 313 372 303 365 433 463 350 412 429 394 426 380 271 292\n",
      " 375 451 307 417 370 369 387 398 384 458 407 268 491 466 482 334 324 445\n",
      " 421 295 291 314 344 315 422 481 469 318 308 393 490 416 343 521 355 510\n",
      " 373 400 289 409 430 363 487 332 448 390 333 354 388 353 336 325 360 381\n",
      " 374 306 443 415 552 498 511 428 471 432 410 508 447 452 539 519 328 378\n",
      " 401 566 479 347 376 534 582 385 468 441 411 527 392 470 439 449 454 545\n",
      " 537 356 499 574 560 379 395 397 489 555 503 523 562 425 472 345 464 480\n",
      " 406 462 414 496 437 607 361 597 485 362 502 602 500 413 419 446 529 518\n",
      " 548 486 589 399 587 634 382 623 427 513 434 461 581 656 526 404 573 509\n",
      " 483 542 444 383 506 616 467 524 453 553 440 535 625 604 418 644 436 611\n",
      " 532 565 456 547 477 504 627 559 465 488 528 600 578 665 674 423 546 638\n",
      " 647 435 405 640 460 476 683 525 620 649 667 601 658 586 507 474 692 655\n",
      " 455 442 420 484 579 556 493 591 550 572 515 505 459 530 438 475 497 570\n",
      " 708 643 621 577 672 685 594 605 609 598 698 501 675 668 544 599 618 516\n",
      " 626 457 473 520 495 699 522 688 642 660 684 567 691 714 538 719 593 633\n",
      " 615 549 492 728 704 645 514 536 676 569 636 610 659 558 590 705 723 697\n",
      " 540 712 543 652 617 478 641 568 512 494 657 563 711 637 690 653 592 673\n",
      " 576 632 666 722 718 717 533 608 735 731 557 661 629 583 612 554 741 725\n",
      " 678 575 531 517 595 729 720 702 671 669 648 686 654 680 726 585 737 743\n",
      " 603 727 651 736 701 733 715 747 694 732 682 664 696 670 687 571 551 541\n",
      " 613 596 635 622 588 703 619 738 749 564 700 624 734 742 713 748 663 739\n",
      " 650 631 614 681 706 561 695 679 724 751 689 580 662 677 630 584 606 628\n",
      " 750 745 710 744 639 740 746 721 730 707 709 693 716 646]\n",
      "[  5   4   6  14   7   3  11  17  23   2   0   1  18  21  22  20  19  12\n",
      "  16  13  10  15   8   9  27  38  25  44  35  26  39  49  30  52  28  41\n",
      "  29  34  32  24  46  51  45  48  37  33  40  47  50  76  67  56  71  65\n",
      "  42  72  36  63  61  59  43  54  79  57  73  77  58  66  31  74  64  81\n",
      "  60  92 101 100 111  68 105  53  98 104  93  91  83  85  62  86  94 110\n",
      "  84  75  89  55  99  78 126 132  69  70 116 108 121  80  88 140 106 118\n",
      "  82 120 127  95 129 107 117  97 138 125 119 137 122 164  96 133 130 156\n",
      " 144 172 142 114 131 109 151 153 158  87 143 175 166 160  90 154 102 141\n",
      " 167 188 148 171 169 203 103 128 113 189 136 185 168 123 150 162 115 182\n",
      " 191 183 165 152 145 198 124 192 135 179 229 210 195 155 177 212 112 196\n",
      " 134 213 208 193 211 194 216 176 234 146 215 163 245 238 202 223 260 239\n",
      " 237 222 220 209 204 241 186 178 263 139 147 243 199 217 161 149 159 230\n",
      " 250 276 200 249 267 184 173 246 247 157 265 170 228 290 266 261 226 295\n",
      " 225 206 273 242 284 180 218 262 190 251 187 253 201 227 256 279 326 283\n",
      " 303 317 294 289 174 297 205 274 304 292 280 248 275 302 235 207 320 309\n",
      " 301 181 323 224 299 347 281 331 319 214 311 329 252 359 272 285 373 219\n",
      " 335 380 349 353 338 197 324 389 345 360 358 307 300 296 322 232 325 269\n",
      " 293 240 244 306 221 258 411 315 255 385 352 288 375 420 236 259 388 321\n",
      " 351 361 231 348 350 333 318 264 277 384 378 381 377 339 341 291 282 271\n",
      " 439 376 367 374 278 405 397 391 409 310 416 407 343 448 257 357 287 418\n",
      " 363 379 298 473 442 330 440 402 467 406 433 369 444 270 432 254 415 233\n",
      " 401 268 398 366 436 312 459 463 400 308 466 426 460 469 328 313 494 429\n",
      " 445 354 410 314 393 430 503 390 396 332 286 327 424 346 334 336 412 305\n",
      " 371 340 421 453 452 525 419 495 485 562 451 532 490 497 510 484 475 364\n",
      " 557 519 316 437 441 511 434 513 457 478 477 368 344 491 521 548 342 395\n",
      " 449 512 356 337 539 417 498 545 471 535 372 544 501 579 567 392 458 362\n",
      " 383 462 365 464 583 524 534 502 613 527 570 483 526 435 517 603 487 492\n",
      " 560 563 479 528 550 404 408 382 394 355 559 386 577 547 632 509 413 399\n",
      " 425 506 581 515 625 428 414 584 596 370 604 586 500 543 565 455 598 546\n",
      " 431 537 423 609 593 620 474 608 644 387 569 523 617 575 427 551 655 531\n",
      " 611 573 447 530 446 558 443 450 641 628 493 663 712 629 595 456 403 472\n",
      " 465 631 549 542 587 638 552 671 597 674 461 486 564 480 422 481 580 468\n",
      " 514 647 576 600 616 658 568 690 683 615 650 610 649 657 634 667 599 664\n",
      " 633 687 675 635 590 594 701 653 673 582 533 627 705 507 662 499 438 482\n",
      " 488 476 676 454 504 682 516 679 553 692 714 508 619 496 614 646 689 605\n",
      " 643 529 685 651 612 718 652 566 518 541 665 626 728 668 630 694 704 622\n",
      " 659 522 536 470 706 702 636 719 698 726 571 695 703 715 737 642 540 684\n",
      " 645 554 670 589 639 654 734 561 678 709 556 717 711 713 489 572 681 724\n",
      " 751 696 723 741 722 729 693 727 744 661 699 660 747 666 592 574 602 505\n",
      " 656 585 555 607 707 672 735 700 677 710 588 725 730 618 736 746 520 732\n",
      " 708 731 601 621 578 748 680 624 669 686 697 623 637 648 538 606 591 640\n",
      " 721 691 742 733 716 740 745 720 739 749 738 743 750 688]\n",
      "[  4   7   8   2   3   6   1   5   0  22  16  12  19  23  20  21  13  18\n",
      "  15  17  11  14   9  10  55  35  25  42  50  43  51  56  36  38  45  39\n",
      "  33  37  49  34  29  32  27  24  28  31  26  30  81  52  88  78  46  74\n",
      "  40  47  53  63  82  41  54  44  48  73  57  65  70  60  58  86  67  68\n",
      "  79  93  84  75  72  64 121  97 100 105  89  69 110  71 119  61  62  87\n",
      "  66  98  90  80  59 111 120  77 154 114 106 103  92 140 126 157 102 137\n",
      " 115  76  94 113 117  85 142 127  99  91 116  83 118 135 133 125 128 149\n",
      " 174 189 155 136 123 170 108 107 186 138  95  96 139 134 156 101 104 184\n",
      " 220 132 180 182 198 166 164 145 124 223 202 169 162 109 216 152 112 122\n",
      " 159 175 158 148 168 131 160 129 153 151 150 144 141 130 188 232 178 248\n",
      " 204 176 256 201 225 185 143 205 171 187 243 193 237 206 146 277 218 287\n",
      " 236 258 263 196 210 190 173 213 161 283 194 203 172 219 227 165 147 217\n",
      " 297 224 288 324 221 245 238 320 222 192 239 255 183 163 240 167 234 177\n",
      " 264 211 191 299 241 261 267 279 235 262 281 271 294 242 252 356 259 333\n",
      " 328 358 318 209 181 208 244 253 179 195 274 199 393 284 200 207 275 369\n",
      " 323 360 298 270 354 296 197 268 387 292 212 229 276 289 308 306 257 228\n",
      " 345 314 226 254 327 321 352 231 309 381 337 300 291 246 423 317 422 392\n",
      " 215 214 280 395 286 303 230 332 425 272 365 409 326 269 452 315 453 346\n",
      " 420 311 251 342 355 377 247 305 348 367 338 233 404 487 484 375 449 250\n",
      " 385 457 293 329 391 266 373 371 361 379 273 363 439 343 336 249 295 341\n",
      " 400 290 394 353 265 396 359 517 313 366 405 312 413 477 340 482 466 515\n",
      " 319 307 260 431 383 282 380 278 412 436 310 416 507 419 458 304 442 410\n",
      " 330 513 376 334 414 285 499 424 549 551 386 325 331 301 441 437 302 462\n",
      " 347 350 397 528 547 467 408 432 576 578 403 444 534 483 440 447 562 468\n",
      " 606 344 474 351 316 465 571 496 417 509 456 553 322 370 493 364 473 430\n",
      " 427 599 464 589 372 621 595 579 388 486 495 448 479 454 628 384 362 519\n",
      " 339 491 335 490 497 537 438 521 357 650 545 406 544 516 520 510 389 612\n",
      " 475 378 471 644 514 559 522 504 618 460 349 602 401 368 567 418 426 584\n",
      " 540 546 481 399 536 492 543 538 374 670 500 565 664 407 636 623 629 530\n",
      " 511 641 566 682 434 443 390 590 428 506 382 415 568 603 550 563 648 591\n",
      " 689 558 659 560 523 445 459 433 398 450 577 698 661 533 666 527 588 620\n",
      " 572 581 680 542 703 582 608 610 402 587 411 609 622 604 478 421 463 592\n",
      " 683 597 561 639 715 605 717 676 627 555 600 451 693 470 548 640 619 727\n",
      " 626 617 580 607 690 480 707 655 614 697 498 489 469 429 564 435 643 616\n",
      " 575 723 624 706 635 673 712 718 730 512 455 586 732 594 634 660 503 446\n",
      " 485 501 632 633 642 662 598 685 611 638 601 613 652 649 678 518 654 532\n",
      " 472 674 647 737 653 719 735 721 725 529 461 505 663 744 686 656 488 476\n",
      " 625 668 675 696 699 671 665 729 541 535 726 615 525 740 630 733 552 701\n",
      " 494 631 677 557 539 739 745 731 734 681 747 713 669 692 637 688 710 502\n",
      " 554 569 679 645 742 684 748 736 738 687 702 695 716 714 658 524 508 570\n",
      " 691 574 646 583 556 749 720 705 651 704 743 750 672 694 657 728 746 667\n",
      " 708 741 711 724 709 531 596 585 593 573 526 700 722 751]\n",
      "[ 14  18   9  21  31  33  24   7  16   3  17   6  13   5  22  27  29   1\n",
      "   0   4   2  10  15  11  12   8  57  41  35  59  37  54  85  79  75  68\n",
      "  66  28  19  25  34  26  42  23  30  50  20  39  49  43  32  36  56  58\n",
      "  40 122  52 119  67 132  71  44  46  45  38  69 101  84  63  51  88  96\n",
      "  87  64  97  55  60  90 186  78  91  61  82  70 149 172  72  47 118  62\n",
      " 130 142  53  65 170  48  74  73 148 166  89  80 111  83  76 103  92 182\n",
      "  86 159  77 107 153  93 195  95 102 120 106 152 184 165  81 112 104 151\n",
      "  94 109 168 144 135 136 128 147  99 158 105 141 121  98 140 131 108 110\n",
      " 116 185 312 313 203 447 100 181 401 516 335 373 208 139 173 123 191 154\n",
      " 204 253 254 115 190 194 133 167 129 150 113 114 216 201 163 134 233 145\n",
      " 138 155 124 125 176 328 137 329 117 267 245 374 169 193 388 126 365 161\n",
      " 127 237 311 189 156 143 175 146 412 164 265 379 296 304 302 205 160 183\n",
      " 180 239 225 218 177 157 171 209 187 274 211 333 162 367 207 320 220 343\n",
      " 179 197 178 188 653 215 518 229 199 303 226 241 438 439 202 224 246 232\n",
      " 210 442 174 289 543 529 337 200 248 214 263 221 228 339 372 293 325 306\n",
      " 400 316 307 308 213 242 244 261 238 231 404 196 198 206 192 217 222 223\n",
      " 355 633 724 758 777 219 235 264 230 268 712 212 327 310 623 622 277 247\n",
      " 294 285 301 250 368 408 286 284 377 356 437 370 394 251 357 398 378 236\n",
      " 234 315 281 470 275 472 288 227 257 321 260 240 255 272 249 300 426 338\n",
      " 292 319 663 252 243 270 258 571 417 273 287 667 464 278 654 570 342 279\n",
      " 314 722 552 309 299 652 578 271 446 499 457 706 295 282 650 677 563 363\n",
      " 432 332 375 424 269 371 384 352 318 259 561 354 266 636 637 534 280 340\n",
      " 697 347 297 291 324 350 323 383 483 391 283 256 331 262 702 473 606 713\n",
      " 682 276 376 506 290 410 380 336 364 298 386 351 507 425 346 322 643 348\n",
      " 620 714 560 514 405 540 362 305 500 569 592 381 769 531 436 387 317 419\n",
      " 330 800 353 808 326 546 479 344 427 440 816 488 803 775 360 768 411 433\n",
      " 519 547 668 385 577 624 402 557 345 435 415 452 382 407 465 420 341 666\n",
      " 359 429 366 525 409 527 521 334 750 801 791 449 403 482 358 361 396 793\n",
      " 431 785 490 474 742 349 741 390 414 422 451 496 655 584 428 599 508 448\n",
      " 717 369 395 413 453 421 389 728 392 736 462 501 611 674 747 630 687 562\n",
      " 689 523 484 688 478 469 477 480 657 756 430 393 639 757 693 461 487 481\n",
      " 466 434 526 423 780 786 491 744 397 441 399 790 787 533 495 459 550 662\n",
      " 626 456 406 564 627 524 458 504 416 486 509 444 672 505 733 734 617 708\n",
      " 621 647 418 485 471 463 536 460 824 812 538 535 579 493 726 692 678 825\n",
      " 822 827 594 553 810 467 510 809 597 595 640 445 576 748 497 598 738 520\n",
      " 548 609 555 715 694 512 735 528 530 625 572 443 450 701 673 711 749 455\n",
      " 502 703 549 802 718 517 632 581 468 583 522 798 772 498 789 707 475 805\n",
      " 788 574 551 811 566 614 743 558 503 454 723 541 781 651 729 755 610 565\n",
      " 656 476 686 773 635 580 544 607 716 616 754 492 778 727 489 603 763 590\n",
      " 730 539 600 605 764 588 613 739 814 658 783 513 782 494 649 612 545 821\n",
      " 573 601 806 819 515 567 799 665 710 719 779 681 732 685 671 618 631 532\n",
      " 762 537 628 511 770 593 619 634 608 575 589 740 660 680 556 752 826 642\n",
      " 823 761 554 684 559 828 542 776 648 596 753 818 830 695 721 759 709 615\n",
      " 817 676 751 700 829 705 670 679 659 664 774 591 704 704 587 795 586 765\n",
      " 690 720 731 745 737 646 641 604 645 661 696 760 784 568 797 813 820 766\n",
      " 629 796 792 771 725 683 669 675 698 807 815 746 767 794 804 585 582 699\n",
      " 638 602 644 691]\n",
      "[  5  14  12  13   6   2   0   4   8   1  16  13  23  19  19  18  21  20\n",
      "   7   3  15  11  10  17   9  10  22  34  46  25  29  30  42  27  28  27\n",
      "  37  35  31  40  36  50  51  44  38  24  39  33  32  45  47  26  69  63\n",
      "  49  65  75  56  76  83  80  54  66  72  59  53  58  41  71  52  55  57\n",
      "  74  61  70  48  64  43 100  94  79 103  81  96  88  62  89  82  73 104\n",
      "  78  67  99  68  90  98  93  60 114  91  87  77  86 111  95  84 120 113\n",
      " 105  85 127 128  97  92 107 117 125 115 118 122 121 130 149 147 132 109\n",
      " 106 133 108 116 126 112 145 110 146 154 144 102 178 119 185 129 167 166\n",
      " 134 136 151 148 141 131 158 140 137 101 165 155 173 211 191 215 174 170\n",
      " 193 164 139 153 123 163 124 157 135 189 168 171 172 156 190 192 138 183\n",
      " 159 169 180 227 187 197 209 182 196 176 198 226 150 236 199 142 201 162\n",
      " 205 195 217 143 194 248 179 152 213 181 254 229 252 274 225 255 200 212\n",
      " 239 188 246 216 244 231 214 233 160 223 177 207 228 175 221 291 161 208\n",
      " 279 220 260 253 258 259 237 234 210 241 247 275 280 232 314 249 270 268\n",
      " 240 184 186 250 282 324 206 202 265 245 273 302 289 224 266 218 204 261\n",
      " 272 203 294 257 230 271 307 256 312 308 353 281 333 285 286 310 303 372\n",
      " 309 313 297 339 235 389 267 219 222 323 292 278 251 334 298 322 347 332\n",
      " 293 346 277 288 311 238 242 328 315 327 276 306 351 304 336 335 409 426\n",
      " 338 371 373 377 269 361 320 243 264 341 318 329 364 295 317 400 330 403\n",
      " 455 367 438 366 365 394 359 345 290 401 262 381 331 396 296 263 348 354\n",
      " 337 352 287 357 391 388 385 469 301 305 344 430 493 355 386 356 283 284\n",
      " 404 368 374 429 398 379 428 395 421 362 425 321 405 319 384 410 375 520\n",
      " 300 448 363 489 417 424 434 387 449 415 413 380 450 316 340 453 419 378\n",
      " 299 406 478 418 427 408 435 370 325 326 411 483 459 439 407 451 482 552\n",
      " 485 349 392 350 436 523 474 452 441 445 473 513 494 390 528 414 561 508\n",
      " 446 527 471 516 440 464 466 369 431 589 343 463 376 432 484 342 475 457\n",
      " 504 540 437 454 507 358 597 545 472 470 535 393 412 491 621 456 467 498\n",
      " 486 546 397 487 522 548 503 360 582 570 577 529 433 638 420 551 526 416\n",
      " 581 492 512 511 514 650 383 477 500 462 481 495 521 533 565 382 598 604\n",
      " 562 524 600 458 579 517 682 542 488 611 536 656 447 537 510 559 525 402\n",
      " 442 556 505 555 399 605 624 423 549 422 550 567 531 707 530 566 509 568\n",
      " 610 541 637 465 476 583 688 468 585 588 634 584 636 625 560 742 612 662\n",
      " 443 569 497 608 661 635 647 578 592 613 575 553 619 653 490 663 444 593\n",
      " 712 532 591 496 628 615 649 697 698 618 587 655 727 506 601 640 573 501\n",
      " 679 460 515 461 632 759 547 680 622 594 572 671 479 480 639 609 641 657\n",
      " 780 630 667 603 534 544 660 715 700 626 659 648 716 576 768 684 701 543\n",
      " 713 616 738 564 602 689 798 711 668 502 690 725 646 652 737 643 665 729\n",
      " 741 687 499 631 554 623 681 664 563 781 666 704 645 718 571 757 586 795\n",
      " 756 676 760 714 658 685 519 686 807 518 673 747 702 590 735 692 627 745\n",
      " 539 674 709 699 739 538 706 644 765 818 694 771 710 728 805 606 723 596\n",
      " 672 777 721 607 755 683 775 774 693 744 746 819 734 675 782 633 720 620\n",
      " 731 787 791 695 558 793 730 749 790 705 629 817 772 761 557 724 654 789\n",
      " 726 804 802 803 767 799 797 740 766 691 820 736 651 719 753 642 823 776\n",
      " 580 773 764 752 717 574 811 806 827 677 762 732 809 814 769 779 733 595\n",
      " 599 770 813 670 669 796 792 743 750 821 786 824 708 825 810 826 822 754\n",
      " 614 783 617 784 763 801 696 751 703 788 785 758 678 800 748 815 816 794\n",
      " 808 812 778 722]\n",
      "[  12    7    3 ... 1419 1371 1600]\n",
      "[  26   10   18 ... 1079 1543 1530]\n",
      "[ 12   9   8  11   2  10   0   1   4  15  19   5   3  17  14  18   6  22\n",
      "   7  23  27  26  13  24  32  34  21  31  20  30  35  16  40  28  43  25\n",
      "  39  42  29  38  33  48  55  54  37  51  36  50  71  44  66  62  41  45\n",
      "  72  67  80  87  77  83  46  49  47  89 104  95  52  53  92  56  99 106\n",
      " 105 110 124  59  57 114 122  58  63  61 125 119 141 131  60 143  65  68\n",
      "  64 140 161 159 136 146  69 150  74 163  70 180 156 176 165  75 194 196\n",
      " 179  79 170  73 195 214  76  84  78 186 178 212 209 201  81 232 229  82\n",
      " 190  88  86 226  93 216  85 247 205 251 231 268 264  91  97 241 219  90\n",
      " 102 235 283 258  96 286 245  94 271 100 260  98 248 108 300 299 263 308\n",
      " 113 311 276 101 289 103 275 292 107 117 302 322 317 109 290 329 112 304\n",
      " 111 328 312 121 336 301 116 313 115 127 320 335 327 344 118 120 318 341\n",
      " 133 309 126 348 349 326 123 138 334 316 354 325 340 129 353 128 333 144\n",
      " 331 359 134 149 339 132 362 345 137 332 153 350 365 367 337 130 370 343\n",
      " 372 356 157 142 135 338 139 360 162 380 375 147 346 342 352 347 167 151\n",
      " 145 385 384 366 173 357 154 371 148 389 351 376 177 355 358 152 158 378\n",
      " 393 397 361 363 394 383 155 402 164 183 406 409 168 160 388 364 187 368\n",
      " 166 172 401 373 413 390 191 369 421 398 175 407 377 169 374 198 425 403\n",
      " 428 379 381 203 171 182 433 386 174 382 185 408 207 410 211 181 189 417\n",
      " 415 439 387 391 423 395 420 217 445 392 184 193 427 422 222 199 188 399\n",
      " 396 448 400 405 432 453 225 431 202 192 459 206 437 197 230 412 404 436\n",
      " 442 411 210 462 465 416 200 237 243 204 215 467 414 471 444 419 426 456\n",
      " 220 475 246 451 418 208 478 213 430 224 481 455 424 252 227 489 218 256\n",
      " 460 429 435 483 255 434 440 484 221 464 233 495 269 223 443 497 438 470\n",
      " 236 501 239 228 506 447 474 273 490 441 446 279 234 479 509 512 450 242\n",
      " 517 249 454 285 238 503 486 449 240 511 452 492 284 521 253 458 294 526\n",
      " 463 487 259 244 498 457 262 298 468 504 531 461 250 493 303 466 254 267\n",
      " 523 472 508 533 536 476 528 266 257 469 514 305 261 538 516 473 307 519\n",
      " 277 480 310 265 280 477 522 543 485 520 527 491 314 545 482 524 274 270\n",
      " 529 488 546 530 281 272 496 315 494 278 321 293 500 532 547 525 548 282\n",
      " 534 297 505 535 499 324 537 510 287 288 542 549 323 502 296 540 291 507\n",
      " 330 539 550 515 513 544 551 319 541 518 306 295]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idApp in range(1,10):\n",
    "    idApp = float(idApp)\n",
    "    \n",
    "    X_train = df1[df1['AppId'] != idApp]\n",
    "    Y_train = df1[df1['AppId'] != idApp]['duration']\n",
    "    X_test = df1[df1['AppId'] == idApp]\n",
    "    Y_test = df1[df1['AppId'] == idApp]['duration']\n",
    "\n",
    "\n",
    "    yTrain = np.log(Y_train + 0.01)\n",
    "    yTest = np.log(Y_test + 0.01)\n",
    "\n",
    "    #lab = preprocessing.LabelEncoder()\n",
    "    #y_transformed = lab.fit_transform(yTrain)\n",
    "    yTrain_labels = LabelEncoder()\n",
    "    yTrain = yTrain_labels.fit_transform(yTrain)\n",
    "    yTest = yTrain_labels.fit_transform(yTest)\n",
    "    nb_model =  MultinomialNB()\n",
    "    nb_model.fit(X_train, yTrain)\n",
    "\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    print(yTest)\n",
    "    #print(metrics.classification_report(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luan/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application:  1.0   0.9726540657515264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luan/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application:  2.0   9.573538457631496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luan/cuda_project/naive_bayes.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luan/cuda_project/naive_bayes.ipynb#ch0000003?line=14'>15</a>\u001b[0m \u001b[39m#naive_bayes = MultinomialNB()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luan/cuda_project/naive_bayes.ipynb#ch0000003?line=15'>16</a>\u001b[0m linear_svc \u001b[39m=\u001b[39m LinearSVC()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luan/cuda_project/naive_bayes.ipynb#ch0000003?line=16'>17</a>\u001b[0m clf_naive_bayes \u001b[39m=\u001b[39m linear_svc\u001b[39m.\u001b[39;49mfit(X_train,yTrain)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luan/cuda_project/naive_bayes.ipynb#ch0000003?line=18'>19</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf_naive_bayes\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luan/cuda_project/naive_bayes.ipynb#ch0000003?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mApplication: \u001b[39m\u001b[39m'\u001b[39m, idApp,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, mean_absolute_percentage_error(yTest, y_pred))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:257\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    254\u001b[0m check_classification_targets(y)\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, n_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[1;32m    258\u001b[0m     X,\n\u001b[1;32m    259\u001b[0m     y,\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    264\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty,\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[1;32m    266\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    268\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulti_class,\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    272\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[39m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m n_iter_\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1205\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1202\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m   1204\u001b[0m solver_type \u001b[39m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1205\u001b[0m raw_coef_, n_iter_ \u001b[39m=\u001b[39m liblinear\u001b[39m.\u001b[39;49mtrain_wrap(\n\u001b[1;32m   1206\u001b[0m     X,\n\u001b[1;32m   1207\u001b[0m     y_ind,\n\u001b[1;32m   1208\u001b[0m     sp\u001b[39m.\u001b[39;49misspmatrix(X),\n\u001b[1;32m   1209\u001b[0m     solver_type,\n\u001b[1;32m   1210\u001b[0m     tol,\n\u001b[1;32m   1211\u001b[0m     bias,\n\u001b[1;32m   1212\u001b[0m     C,\n\u001b[1;32m   1213\u001b[0m     class_weight_,\n\u001b[1;32m   1214\u001b[0m     max_iter,\n\u001b[1;32m   1215\u001b[0m     rnd\u001b[39m.\u001b[39;49mrandint(np\u001b[39m.\u001b[39;49miinfo(\u001b[39m\"\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmax),\n\u001b[1;32m   1216\u001b[0m     epsilon,\n\u001b[1;32m   1217\u001b[0m     sample_weight,\n\u001b[1;32m   1218\u001b[0m )\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[39m# srand supports\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m n_iter_max \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n_iter_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idApp in range(1,10):\n",
    "    idApp = float(idApp)\n",
    "    \n",
    "    X_train = df1[df1['AppId'] != idApp]\n",
    "    Y_train = df1[df1['AppId'] != idApp]['duration']\n",
    "    X_test = df1[df1['AppId'] == idApp]\n",
    "    Y_test = df1[df1['AppId'] == idApp]['duration']\n",
    "\n",
    "    yTrain = pd.Series(np.log(Y_train + 0.0001), dtype=np.int64, name='Numbers')\n",
    "\n",
    "    #yTrain = np.log(Y_train + 0.01)\n",
    "\n",
    "    yTest = np.log(Y_test + 0.01)\n",
    "\n",
    "    #naive_bayes = MultinomialNB()\n",
    "    linear_svc = LinearSVC()\n",
    "    clf_naive_bayes = linear_svc.fit(X_train,yTrain)\n",
    "\n",
    "    y_pred = clf_naive_bayes.predict(X_test)\n",
    "    \n",
    "    print('Application: ', idApp,' ', mean_absolute_percentage_error(yTest, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
